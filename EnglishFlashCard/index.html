<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Voice Flashcards</title>
  <style>
    :root { --bg:#0f1220; --fg:#e6e8f2; --muted:#9aa1b2; --btn:#4f63ff; }
    html,body{margin:0;height:100%;background:var(--bg);color:var(--fg);font:16px/1.5 system-ui,-apple-system,Segoe UI,Roboto;}
    .wrap{max-width:840px;margin:0 auto;padding:24px 16px}
    h1{margin:0 0 12px;font-weight:700}
    .card{background:#151a2e;border:1px solid #222745;border-radius:12px;padding:16px;margin:16px 0}
    label{display:block;margin:8px 0 6px;color:var(--muted);font-size:0.95rem}
    textarea,input{width:100%;box-sizing:border-box;background:#0e1330;color:var(--fg);border:1px solid #283053;border-radius:10px;padding:12px}
    .row{display:flex;gap:8px;flex-wrap:wrap;margin-top:10px}
    button{appearance:none;border:0;border-radius:10px;padding:12px 14px;background:var(--btn);color:white;font-weight:600;cursor:pointer}
    button.secondary{background:#263158}
    button:disabled{opacity:.5;cursor:not-allowed}
    small{color:var(--muted)}
    .hidden{display:none}
  </style>
</head>
<body>
  <div class="wrap">
    <h1>Voice Flashcards</h1>
    <p class="card" id="notice" style="display:none"></p>

    <div class="card">
      <label for="prompt">Speak or type your phrase</label>
      <textarea id="prompt" rows="4" placeholder="Say it or type here..."></textarea>

      <div class="row">
        <button id="btn-mic">üéôÔ∏è Speak</button>
        <button id="btn-stop" class="secondary" disabled>‚èπÔ∏è Stop</button>
        <button id="btn-speak" class="secondary">üîà Read Aloud</button>
        <button id="btn-save" class="secondary">üíæ Save Flashcard</button>
      </div>
      <small id="hint">Tip: On iPhone/iPad, use typing; in-browser speech input isn‚Äôt supported.</small>
    </div>

    <div class="card">
      <label for="improved">Improved (AI-rewritten) output</label>
      <textarea id="improved" rows="4" placeholder="Your polished text will appear here..."></textarea>
      <div class="row">
        <button id="btn-rewrite">‚ú® Improve with AI</button>
      </div>
    </div>
  </div>

  <script>
    // ---------- Capability detection ----------
    const ua = navigator.userAgent || '';
    const isIOSLike = /iPad|iPhone|iPod/.test(ua) ||
                      (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1); // iPadOS
    const NativeSR = window.SpeechRecognition || window.webkitSpeechRecognition || null;
    const supportsSpeechRec = !!NativeSR && !isIOSLike; // block on iOS (Safari & Chrome)

    // UI elements
    const noticeEl = document.getElementById('notice');
    const micBtn   = document.getElementById('btn-mic');
    const stopBtn  = document.getElementById('btn-stop');
    const speakBtn = document.getElementById('btn-speak');
    const saveBtn  = document.getElementById('btn-save');
    const rewriteBtn = document.getElementById('btn-rewrite');
    const promptEl = document.getElementById('prompt');
    const improvedEl = document.getElementById('improved');
    const hintEl   = document.getElementById('hint');

    // Explain limitations to the user (and disable mic on iOS)
    if (!supportsSpeechRec) {
      micBtn.disabled = true;
      hintEl.textContent = "Voice input isn‚Äôt supported in iOS browsers. Please type instead, or use the server transcription fallback.";
      showNotice("Speech Error: service-not-allowed ‚Äî iOS Safari/Chrome do not support in-browser speech recognition. Mic is disabled here; typing still works. Text-to-speech is available via the Read Aloud button.");
    }

    function showNotice(msg) {
      noticeEl.textContent = msg;
      noticeEl.style.display = 'block';
    }

    // ---------- Text-to-Speech (works on iOS if triggered by user gesture) ----------
    function speakText(text) {
      try {
        window.speechSynthesis.cancel();
        const u = new SpeechSynthesisUtterance(text);
        // You can set u.lang = 'en-GB' if you prefer
        window.speechSynthesis.speak(u);
      } catch (e) {
        showNotice("Could not play speech: " + (e?.message || e));
      }
    }

    speakBtn.addEventListener('click', () => {
      const text = (improvedEl.value || promptEl.value || "").trim();
      if (!text) return showNotice("Nothing to read yet.");
      speakText(text);
    });

    // ---------- Speech Recognition (desktop only) ----------
    let rec = null;
    if (supportsSpeechRec) {
      rec = new NativeSR();
      rec.lang = 'en-US';
      rec.interimResults = true;
      rec.continuous = true;

      rec.onresult = (evt) => {
        let transcript = '';
        for (let i = evt.resultIndex; i < evt.results.length; i++) {
          transcript += evt.results[i][0].transcript;
        }
        promptEl.value = transcript.trim();
      };

      rec.onend = () => {
        micBtn.disabled = false;
        stopBtn.disabled = true;
      };

      rec.onerror = (e) => {
        // Common: "not-allowed" if mic permission denied
        showNotice("Speech Error: " + e.error);
        micBtn.disabled = false;
        stopBtn.disabled = true;
      };
    }

    micBtn.addEventListener('click', async () => {
      if (!supportsSpeechRec) return; // safety
      try {
        noticeEl.style.display = 'none';
        micBtn.disabled = true;
        stopBtn.disabled = false;
        rec.start(); // must be inside a user gesture
      } catch (e) {
        showNotice("Speech start failed: " + (e?.message || e));
        micBtn.disabled = false;
        stopBtn.disabled = true;
      }
    });

    stopBtn.addEventListener('click', () => {
      try { rec && rec.stop(); } catch {}
      micBtn.disabled = false;
      stopBtn.disabled = true;
    });

    // ---------- Hooks to your app logic ----------
    // TODO: Replace the placeholders with your actual calls.
    // 1) Improve/Rephrase with Gemini (call your server or Firebase Function; don't call Gemini from the browser with a raw key).
    rewriteBtn.addEventListener('click', async () => {
      const text = promptEl.value.trim();
      if (!text) return showNotice("Type or speak something first.");
      try {
        // TODO: call your backend, e.g. fetch('/rewrite', {method:'POST', body: JSON.stringify({text})})
        // const { improved } = await (await fetch('/rewrite', {...})).json();
        const improved = "[demo] " + text; // placeholder
        improvedEl.value = improved;
      } catch (e) {
        showNotice("Rewrite failed: " + (e?.message || e));
      }
    });

    // 2) Save flashcard (to Firestore when signed-in; fallback to localStorage if signed-out)
    saveBtn.addEventListener('click', async () => {
      const front = promptEl.value.trim();
      const back  = improvedEl.value.trim();
      if (!front || !back) return showNotice("Need both original and improved text to save a card.");
      try {
        // TODO: call your saveCard(front, back)
        // await saveCard({front, back});
        showNotice("Saved ‚úîÔ∏è (placeholder)");
      } catch (e) {
        showNotice("Save failed: " + (e?.message || e));
      }
    });

    // ---------- Optional: server transcription fallback for iOS ----------
    // If you later want mic on iOS, implement a record‚Üíupload‚Üíserver-STT path.
    // Keep the UI button hidden/disabled until that path exists.
  </script>
</body>
</html>